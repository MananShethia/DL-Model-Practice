import tensorflow as tf

def train():
    strategy = tf.distribute.MirroredStrategy(devices=['/gpu:2', '/gpu:3'])
    
    with strategy.scope():
        model = cloud_net_model.model_arch(input_rows=in_rows,
                                           input_cols=in_cols,
                                           num_of_channels=num_of_channels,
                                           num_of_classes=num_of_classes)
        model.compile(optimizer=Adam(lr=starting_learning_rate), loss=jacc_coef, metrics=[jacc_coef])
        # model.summary()

        model_checkpoint = ModelCheckpoint(weights_path, monitor='val_loss', save_best_only=True)
        lr_reducer = ReduceLROnPlateau(factor=decay_factor, cooldown=0, patience=patience, min_lr=end_learning_rate, verbose=1)
        csv_logger = CSVLogger(experiment_name + '_log_1.log')

        train_img_split, val_img_split, train_msk_split, val_msk_split = train_test_split(train_img, train_msk,
                                                                                          test_size=val_ratio,
                                                                                          random_state=42, shuffle=True)

        if train_resume:
            model.load_weights(weights_path)
            print("\nTraining resumed...")
        else:
            print("\nTraining started from scratch... ")

        print("Experiment name: ", experiment_name)
        print("Input image size: ", (in_rows, in_cols))
        print("Number of input spectral bands: ", num_of_channels)
        print("Learning rate: ", starting_learning_rate)
        print("Batch size: ", batch_sz, "\n")

        model.fit_generator(
            generator=mybatch_generator_train(list(zip(train_img_split, train_msk_split)), in_rows, in_cols, batch_sz, max_bit),
            steps_per_epoch=np.ceil(len(train_img_split) / batch_sz), epochs=max_num_epochs, verbose=1,
            validation_data=mybatch_generator_validation(list(zip(val_img_split, val_msk_split)), in_rows, in_cols, batch_sz, max_bit),
            validation_steps=np.ceil(len(val_img_split) / batch_sz),
            callbacks=[model_checkpoint, lr_reducer, ADAMLearningRateTracker(end_learning_rate), csv_logger])
