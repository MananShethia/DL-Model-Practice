with strategy.scope():
    # Define model, optimizer, loss function, and callbacks
    model = cloud_net_model.model_arch(input_rows=in_rows,
                                       input_cols=in_cols,
                                       num_of_channels=num_of_channels,
                                       num_of_classes=num_of_classes)
    optimizer = Adam(lr=starting_learning_rate)
    loss_fn = jacc_coef
    metrics = [jacc_coef]

    # Compile the model
    model.compile(optimizer=optimizer, loss=loss_fn, metrics=metrics)

    # Define callbacks
    model_checkpoint = ModelCheckpoint(weights_path, monitor='val_loss', save_best_only=True)
    lr_reducer = ReduceLROnPlateau(factor=decay_factor, cooldown=0, patience=patience, min_lr=end_learning_rate, verbose=1)
    csv_logger = CSVLogger(experiment_name + '_log_1.log')

    # Split the data for training and validation
    train_img_split, val_img_split, train_msk_split, val_msk_split = train_test_split(train_img, train_msk,
                                                                                      test_size=val_ratio,
                                                                                      random_state=42, shuffle=True)

    if train_resume:
        model.load_weights(weights_path)
        print("\nTraining resumed...")
    else:
        print("\nTraining started from scratch... ")

    print("Experiment name: ", experiment_name)
    print("Input image size: ", (in_rows, in_cols))
    print("Number of input spectral bands: ", num_of_channels)
    print("Learning rate: ", starting_learning_rate)
    print("Batch size: ", batch_sz, "\n")

    # Define batch size per GPU
    global_batch_size = batch_sz * strategy.num_replicas_in_sync
    train_steps_per_epoch = np.ceil(len(train_img_split) / global_batch_size)
    val_steps_per_epoch = np.ceil(len(val_img_split) / global_batch_size)

    # Define training and validation datasets
    train_dataset = tf.data.Dataset.from_generator(
        lambda: mybatch_generator_train(list(zip(train_img_split, train_msk_split)), in_rows, in_cols, batch_sz, max_bit),
        output_types=(tf.float32, tf.float32),
        output_shapes=([None, in_rows, in_cols, num_of_channels], [None, in_rows, in_cols, num_of_classes])
    ).batch(global_batch_size)

    val_dataset = tf.data.Dataset.from_generator(
        lambda: mybatch_generator_validation(list(zip(val_img_split, val_msk_split)), in_rows, in_cols, batch_sz, max_bit),
        output_types=(tf.float32, tf.float32),
        output_shapes=([None, in_rows, in_cols, num_of_channels], [None, in_rows, in_cols, num_of_classes])
    ).batch(global_batch_size)

    # Train the model
    model.fit(train_dataset, epochs=max_num_epochs, verbose=1, steps_per_epoch=train_steps_per_epoch,
              validation_data=val_dataset, validation_steps